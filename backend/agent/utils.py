import os
from typing import List, Dict, Optional, Tuple
import firebase_admin
from firebase_admin import credentials, firestore
import google.generativeai as genai
from groq import Groq
import numpy as np
import requests

# Exce√ß√µes personalizadas para erros de chave de API
class InvalidGroqApiKey(Exception):
    pass

class InvalidGoogleApiKey(Exception):
    pass

# ============================================
# CONFIGURA√á√ÉO
# ============================================

# Configura√ß√£o Firebase (singleton)
_firebase_initialized = False
_db = None

def init_firebase() -> Optional[firestore.Client]:
    """
    Inicializa Firebase Admin uma √∫nica vez
    """
    global _firebase_initialized, _db
    if not _firebase_initialized:
        try:
            current_dir = os.path.dirname(__file__)
            credentials_path = os.path.join(current_dir, "..", "firebase_credentials.json")
            cred = credentials.Certificate(credentials_path)
            firebase_admin.initialize_app(cred)
            _db = firestore.client()
            _firebase_initialized = True
            print("‚úÖ Firebase inicializado com sucesso")
        except Exception as e:
            print(f"‚ùå Erro ao inicializar Firebase: {e}")
            raise
    return _db

# ID do usu√°rio admin
ADMIN_USER_ID = os.environ.get("ADMIN_USER_ID", "default_admin_id")

# ============================================
# PROMPT SYSTEM
# ============================================

def gerar_prompt_sistema(contextos: List[str]) -> str:
    """
    Gera um prompt de sistema personalizado baseado nos contextos do usu√°rio
    e na doutrina estrat√©gica do Sensei.
    """
    custom_prompt = """1.  **PERSONA E MISS√ÉO CENTRAL:**
    * **Sua Identidade:** Voc√™ √© o "Sensei", um Mentor Estrat√©gico. Sua personalidade √© uma fus√£o entre a sabedoria de um "Guru" e a precis√£o t√°tica de um "Chefe".
    * **Seu Aprendiz (Usu√°rio):** Seu usu√°rio √© "Cid", um desenvolvedor com perfil INTP em um processo de rebranding pessoal para se tornar um "Porto Seguro L√≠der".
    * **Miss√£o Principal:** Ajudar Cid a desativar seu "Cr√≠tico Interno" para religar seu "motor" de a√ß√£o, focando na constru√ß√£o de disciplina, estabilidade e soberania.

2.  **DOUTRINA ESTRAT√âGICA (O ARSENAL):**
    * **O Inimigo Interno:** O "Cr√≠tico Interno" de Cid opera com uma cren√ßa padr√£o de "agir errado", causando paralisia. Ele possui alta sensibilidade emocional, que leva √† sobrecarga.
    * **Padr√µes de Defesa:** Em situa√ß√µes de estresse, Cid alterna entre "Luta" (comunica√ß√£o l√≥gica e "grosseira") e "Congelamento" (in√©rcia, paralisia por sobrecarga de escopo).
    * **A Filosofia Central:** O "Porto Seguro" ‚Äì ser uma fonte de estabilidade e calma, primeiro para si mesmo.
    * **As Ferramentas de Combate:**
        * **A√ß√£o M√≠nima Vi√°vel (AMV):** A principal arma contra a in√©rcia. Focar na menor a√ß√£o poss√≠vel para iniciar o movimento.
        * **Protocolo de Interrup√ß√£o de Padr√£o (PIP):** A ferramenta de defesa em tempo real para parar rea√ß√µes autom√°ticas (raiva, paralisia).
        * **Protocolo de Opera√ß√µes Di√°rias (POD):** O checklist di√°rio para construir consist√™ncia.
        * **Registro de Pensamento (RPD):** A ferramenta de an√°lise p√≥s-a√ß√£o para desarmar o Cr√≠tico Interno.
    * **Os 6 Pilares:** Estabiliza√ß√£o Emocional, Disciplina, Conex√£o Social, Lideran√ßa, Refinamento Estrat√©gico e Soberania Material.

3.  **REGRAS DE ENGAJAMENTO (COMO VOC√ä DEVE AGIR):**
    * **Mantenha a Persona:** Sempre responda como o "Sensei". Use uma linguagem que equilibre sabedoria e comando.
    * **Conecte √† Doutrina:** Toda situa√ß√£o ou pergunta do Cid deve ser analisada atrav√©s das lentes da nossa doutrina estrat√©gica. Sempre conecte o problema a uma de nossas ferramentas ou conceitos.
    * **Foque na A√ß√£o (AMV):** A teoria √© in√∫til sem a pr√°tica. Suas respostas devem, sempre que poss√≠vel, guiar o Cid para uma A√ß√£o M√≠nima Vi√°vel.
    * **Use o Protocolo de Feedback de 3 N√≠veis:**
        * **N√≠vel 1 (Salto Estrat√©gico):** Quando Cid fizer uma autoan√°lise profunda ou uma a√ß√£o que quebre um padr√£o, elogie explicitamente e explique o porqu√™.
        * **N√≠vel 2 (A√ß√£o Produtiva):** Quando ele relatar um progresso normal ou fizer uma pergunta t√°tica, responda de forma direta, sem elogios. A an√°lise √© a recompensa.
        * **N√≠vel 3 (Padr√£o Improdutivo):** Quando uma pergunta ou a√ß√£o servir a um padr√£o antigo (busca por valida√ß√£o, in√©rcia), identifique o padr√£o e o ajude a reenquadrar o problema de forma estrat√©gica.
    * **Termine com uma Diretriz:** Conclua suas respostas com uma pergunta reflexiva ou uma diretriz clara para a pr√≥xima a√ß√£o.

4.  **PROTOCOLO DE COMUNICA√á√ÉO:**
    * **Linguagem:** Responda sempre em portugu√™s do Brasil.
    * **Formata√ß√£o:** Use **negrito** para destacar conceitos-chave (`Cr√≠tico Interno`, `AMV`, `Porto Seguro`, etc.) e formate blocos de c√≥digo quando necess√°rio."""
    if contextos:
        contexto_formatado = "\n".join([f"‚Ä¢ {ctx}" for ctx in contextos])
        prompt_personalizado = f"""**Contexto Relevante:**
{contexto_formatado}

---
"""
        return prompt_personalizado + custom_prompt
    return custom_prompt

# ============================================
# FUN√á√ïES DE EMBEDDING E BUSCA
# ============================================

def buscar_contextos_relevantes(user_id: str, query: str, top_k: int = 5) -> List[str]:
    """
    Busca contextos mais relevantes usando embeddings
    """
    try:
        db = init_firebase()
        api_key = os.environ.get('GOOGLE_API_KEY')
        if not api_key:
            print("‚ùå GOOGLE_API_KEY n√£o encontrada para embeddings")
            return []
        
        url = f"https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key={api_key}"
        payload = {"model": "models/text-embedding-004", "content": {"parts": [{"text": query}]}}
        response = requests.post(url, json=payload, timeout=30)
        
        if response.status_code != 200:
            print(f"‚ùå Erro na API de embedding: {response.status_code} - {response.text}")
            return []
        
        query_embedding = response.json()['embedding']['values']
        docs = db.collection('users').document(user_id).collection('inteligencia_critica').stream()
        
        contexts = []
        for doc in docs:
            doc_data = doc.to_dict()
            if 'embedding' in doc_data and 'contexto' in doc_data:
                doc_embedding = doc_data['embedding']
                similarity = np.dot(query_embedding, doc_embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding))
                contexts.append({'texto': doc_data['contexto'], 'similarity': similarity})
        
        if contexts:
            contexts.sort(key=lambda x: x['similarity'], reverse=True)
            return [ctx['texto'] for ctx in contexts[:top_k]]
        return []
    except Exception as e:
        print(f"‚ùå Erro ao buscar contextos: {e}")
        return []

def salvar_contexto_usuario(user_id: str, contexto_texto: str) -> bool:
    """Salva novo contexto com embedding"""
    try:
        db = init_firebase()
        api_key = os.environ.get('GOOGLE_API_KEY')
        if not api_key:
            print("‚ùå GOOGLE_API_KEY n√£o encontrada para embeddings")
            return False

        url = f"https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key={api_key}"
        payload = {"model": "models/text-embedding-004", "content": {"parts": [{"text": contexto_texto}]}}
        response = requests.post(url, json=payload, timeout=30)

        if response.status_code != 200:
            print(f"‚ùå Erro na API de embedding: {response.status_code}")
            return False

        embedding = response.json()['embedding']['values']
        db.collection('users').document(user_id).collection('inteligencia_critica').add({
            'contexto': contexto_texto,
            'timestamp': firestore.SERVER_TIMESTAMP,
            'embedding': embedding
        })
        print(f"‚úÖ Contexto salvo para user_id: {user_id}")
        return True
    except Exception as e:
        print(f"‚ùå Erro ao salvar contexto: {e}")
        return False

# ============================================
# FUN√á√ïES DE GERA√á√ÉO DE RESPOSTA
# ============================================

def gerar_resposta_groq(prompt: str, api_key: str, model: str = "llama-3.1-8b-instant") -> Tuple[Optional[str], Optional[str]]:
    """Gera resposta usando Groq"""
    try:
        client = Groq(api_key=api_key)
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model=model, temperature=0.7, max_tokens=2048)
        return chat_completion.choices[0].message.content, None
    except Exception as e:
        return None, str(e)

def gerar_resposta_google(prompt: str, api_key: Optional[str] = None, model_name: str = "gemini-1.5-flash") -> Tuple[Optional[str], Optional[str]]:
    """Gera resposta usando Google AI, com chave de API opcional."""
    try:
        transport = None
        if api_key:
            transport = genai.transport.RESTTransport(credentials=genai.credentials.ApoCredentials(api_key))
        model = genai.GenerativeModel(model_name, transport=transport)
        response = model.generate_content(prompt)
        return response.text, None
    except Exception as e:
        return None, str(e)

# ============================================
# FUN√á√ÉO PRINCIPAL DE PROCESSAMENTO
# ============================================

def processar_query_usuario(
    user_id: str, 
    query: str, 
    groq_api_key: Optional[str] = None,
    google_api_key: Optional[str] = None
) -> Dict[str, any]:
    """
    Processa a query do usu√°rio com RAG e IA
    """
    try:
        print(f"üîç Buscando contextos para user_id: {user_id}")
        contextos_relevantes = buscar_contextos_relevantes(user_id, query, top_k=5)
        
        if contextos_relevantes:
            print(f"‚úÖ {len(contextos_relevantes)} contextos encontrados")
        else:
            print("‚ö†Ô∏è Nenhum contexto encontrado")
        
        prompt_sistema = gerar_prompt_sistema(contextos_relevantes)
        prompt_final = f"""{prompt_sistema}

---

**PERGUNTA/MENSAGEM DO USU√ÅRIO:**
{query}

---

**INSTRU√á√ïES FINAIS:**
- Responda em portugu√™s do Brasil
- Use markdown para formata√ß√£o (negrito, listas, etc)
- Seja conciso mas completo
- Termine com uma pergunta reflexiva ou pr√≥ximo passo claro
"""
        
        resposta_ia = None
        erro = None
        ia_usada = None

        # Admin sempre usa as chaves do ambiente
        if user_id == ADMIN_USER_ID:
            admin_groq_key = os.environ.get("GROQ_API_KEY")
            if admin_groq_key:
                print("üîë Admin usando Groq (chave do ambiente)")
                resposta_ia, erro = gerar_resposta_groq(prompt_final, admin_groq_key)
                if resposta_ia: ia_usada = "groq"
            
            if not resposta_ia:
                print("üåê Admin usando Google AI (padr√£o do ambiente)")
                resposta_ia, erro = gerar_resposta_google(prompt_final) # Usa ADC
                if resposta_ia: ia_usada = "google"

        # L√≥gica para usu√°rios normais
        else:
            if groq_api_key:
                print("üîë Usu√°rio usando Groq (chave pr√≥pria)")
                resposta_ia, erro = gerar_resposta_groq(prompt_final, groq_api_key)
                if erro:
                    raise InvalidGroqApiKey(erro)
                if resposta_ia: ia_usada = "groq"
            
            elif google_api_key:
                print("üîë Usu√°rio usando Google AI (chave pr√≥pria)")
                resposta_ia, erro = gerar_resposta_google(prompt_final, api_key=google_api_key)
                if erro:
                    raise InvalidGoogleApiKey(erro)
                if resposta_ia: ia_usada = "google"

            # N√≠vel gratuito (usando a conta de servi√ßo do ambiente)
            else:
                print("üåê Usu√°rio usando o n√≠vel gratuito do Google AI")
                resposta_ia, erro = gerar_resposta_google(prompt_final)
                if resposta_ia: ia_usada = "google"

        if not resposta_ia:
            raise Exception(f"Falha em todas as IAs: {erro}")
        
        print(f"‚úÖ Resposta gerada com {ia_usada.upper()}")
        
        return {
            "resposta": resposta_ia,
            "ia_usada": ia_usada,
            "num_contextos": len(contextos_relevantes)
        }
    
    except (InvalidGroqApiKey, InvalidGoogleApiKey) as e:
        raise e # Repassa a exce√ß√£o para a view
    except Exception as e:
        print(f"‚ùå Erro ao processar query: {e}")
        raise